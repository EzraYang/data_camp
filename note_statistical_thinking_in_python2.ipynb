{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Thinking in Python (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Parameter estimation by optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Optimal parameters  \n",
    "\n",
    "* 如果你假设数据服从某个分布(例如normal distribution)，而数据真的是这个分布\n",
    "    * calculate parameter from sample data and plug-it-in np.random.normal \n",
    "    * CDF of theoretical population data overlays with ECDF of sample data, then yes you got the optimal params\n",
    "* 如果你假设数据服从某个分布(例如normal distribution)，而数据**并不是**这个分布\n",
    "    * model is wrong, then your np.mean np.std makes no sense\n",
    "    * specifically, when doing linear regression, rely on built-in func to find optimal params."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Linear regression by least squares\n",
    "* It is always a good idea to do some EDA ahead of our analysis\n",
    "    * visual EDA, eg.scatter plot\n",
    "    * quantitative EDA, eg.percentile, pearson correlation coefficient\n",
    "* If result of EDA allows, perform a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this module contains all func I defined for this course\n",
    "from stats_thinking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function stats_thinking.pearson_r>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the illiteracy rate versus fertility\n",
    "_ = plt.plot(illiteracy, fertility, marker='.', linestyle='none')\n",
    "plt.margins(0.02)\n",
    "_ = plt.xlabel('percent illiterate')\n",
    "_ = plt.ylabel('fertility')\n",
    "\n",
    "# Perform a linear regression using np.polyfit(): a, b\n",
    "a, b = np.polyfit(illiteracy, fertility, 1)\n",
    "\n",
    "# Print the results to the screen\n",
    "print('slope =', a, 'children per woman / percent illiterate')\n",
    "print('intercept =', b, 'children per woman')\n",
    "\n",
    "# Make theoretical line to plot\n",
    "x = np.array([0, 100])\n",
    "y = a * x + b\n",
    "\n",
    "# Add regression line to your plot\n",
    "_ = plt.plot(x, y)\n",
    "\n",
    "# Draw the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The importance of EDA: Anscombe's quartet\n",
    "* 下面这四个图 x-mean, y-mean, 直线拟合后的slope和intercept，sum of squared residual几乎完全相等\n",
    "* 然而并不是每个都最适合用直线来拟合\n",
    "* so look before you leap, EDA before any other analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://upload-images.jianshu.io/upload_images/1526845-242eafdc39207d35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Bootstrap confidence intervals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Generating bootstrap replicates\n",
    "* bootstrap -->> resample with replacement\n",
    "* bootstrap sampele -->> a resampled array of data\n",
    "* bootstrap replicate -->> a summary statistic computed from a bootstrap sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.choice(data, len(data))  # draw one bs sample with the same length \n",
    "                                   # as source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualizing bootstrap samples\n",
    "\n",
    "    # 50 bs sample and plot its ecdf\n",
    "for i in range(50):\n",
    "    bs_sample = np.random.choice(rainfall, size=len(rainfall))\n",
    "\n",
    "    x, y = ecdf(bs_sample)\n",
    "    _ = plt.plot(x, y, marker='.', linestyle='none',\n",
    "                 color='gray', alpha=0.1)\n",
    "\n",
    "    # Compute and plot ECDF from original data\n",
    "x, y = ecdf(rainfall)\n",
    "_ = plt.plot(x, y, marker='.')\n",
    "\n",
    "    # Make margins and label axes\n",
    "plt.margins(0.02)\n",
    "_ = plt.xlabel('yearly rainfall (mm)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "\n",
    "    # Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bootstrap confidence intervals\n",
    "* 侧光速的那个家伙并不care这具体的100个sample如何如何；他想知道的是光速population到底咋分布\n",
    "* 用手头100个sample, resample with replacement，重复N次，就得到了N个size=100的sample；相当于从population里重新draw了N次。\n",
    "* N个sample有N个均值 -->>> get a sampling distribution --->> compute confidence interval using np.percentile\n",
    "    * confidence interval: If we repeated measurements over and over again, p% of the observed values would lie within the p% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I've copied this func in 'stats_thinking' module\n",
    "\n",
    "def bootstrap_replicate_1d(data, func):\n",
    "    '''\n",
    "    Take in an array and a aggregate function.\n",
    "    Return one boostrap statistic by passing bs sample to the func.\n",
    "    '''\n",
    "    return func(np.random.choice(data, size=len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I've copied this func in 'stats_thinking' module\n",
    "\n",
    "def draw_bs_reps(data, func, size=1):\n",
    "    \"\"\"\n",
    "    Draw bootstrap replicates.\n",
    "    Return an array of statistics computed from bs samples.\n",
    "    \"\"\"\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
    "\n",
    "    return bs_replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pairs bootstrap\n",
    "* 之前的confidence interval就手头的1D array操作，并不假设它们符合什么模型\n",
    "* 对于假设它们符合linear model的两个array而言，需要pair-wise resample\n",
    "    * resample from np.arange([0, len(x)])  as indices\n",
    "    * use indices to index x-y pairs\n",
    "    * do linear regression using np.polyfit(x_bs, y_bs, 1)multiple times, get multiple statistic(slope & intercept)\n",
    "    * get confidence interval using np.percentile\n",
    "    * or can plot multiple regression lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Introduction to hypothesis testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Formulating and simulating a hypothesis\n",
    "* permutation, used to test if two variables have identical probability distributions. Operation:\n",
    "    * 把两个array合并作一个，打乱重新排序\n",
    "    * 假装前n1个是variable 1，后n2个是variable 2。n1 n2是var1 var2长度\n",
    "    * calculate test stat and p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating permutation sample\n",
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "\n",
    "    # Concatenate the data sets: data\n",
    "    data = np.concatenate((data1, data2))\n",
    "\n",
    "    # Permute the concatenated array: permuted_data\n",
    "    permuted_data = np.random.permutation(data)\n",
    "\n",
    "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "\n",
    "    return perm_sample_1, perm_sample_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test statistics and p-values\n",
    "* 如何来衡量whether or not null hypothesis is true --->> choose a test statistic\n",
    "    * test statistic\n",
    "        * A single number that can be computed from observed data and from data you simulate under the null hypothesis\n",
    "        * It serves as a basis of comparison between the two.\n",
    "        * when choosing a test statistic, The most important thing to consider is: What are you asking?\n",
    "* how can a test statistic indicate whether the null hypothesis is true  --->>> p-value\n",
    "    * p-value\n",
    "        * The probability of obtaining a value of your test statistic that is **at least as extreme as **what was observed, under the assumption the null hypothesis is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a permutation replicate is a single value of a statistic computed from a permutation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating permutation replicates\n",
    "\n",
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: perm_replicates\n",
    "    perm_replicates = np.empty(size)\n",
    "\n",
    "    for i in range(size):\n",
    "        # Generate permutation sample\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
    "\n",
    "        # Compute the test statistic\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "\n",
    "    return perm_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when using a permutation test with a test statistic \n",
    "# of the difference of means to test null hypothesis.\n",
    "\n",
    "    # this is the func\n",
    "def diff_of_means(data_1, data_2):\n",
    "    \"\"\"Difference in means of two arrays.\"\"\"\n",
    "\n",
    "    # The difference of means of data_1, data_2: diff\n",
    "    diff = np.mean(data_1) - np.mean(data_2)\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an example\n",
    "\n",
    "    # empirical test stat from observed data\n",
    "empirical_diff_means = diff_of_means(force_a, force_b)\n",
    "\n",
    "    # 10000 theoretical test stat from generated data\n",
    "perm_replicates = draw_perm_reps(force_a, force_b,\n",
    "                                 diff_of_means, size=10000)\n",
    "\n",
    "    # compare empirical test stat to theoretical test stat: compute p-value: p\n",
    "p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)\n",
    "\n",
    "    # Print the result\n",
    "print('p-value =', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Bootstrap hypothesis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://upload-images.jianshu.io/upload_images/1526845-61864c942922e0b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* one sample test\n",
    "    * campare one set of data into a single number\n",
    "    * 人话解读之课程案例：  \n",
    "    课程中的例子是比较老头A测的a set of 光速和老头B测的光速（只有一个值）    \n",
    "    H_null: 会不会老头B的单一的值才是真正的均值呢？老头A的data set只是个偶然。  \n",
    "    --> 假设H_null成立，老头A的data set是偶然，那就不能用老头A的数据去模拟生成N次实验；  \n",
    "    --> 可以用老头B的单一值作为均值 + 老头A的数据的variance去模拟从population中取N次sample（这里暗含的假设是老头A的variance是有代表性的，老头A只是均值没有代表性）  \n",
    "    --> shifted arrA: arrA - np.mean(arrA) + arrB   \n",
    "    --> emprical test stat: np.mena(arrA) - arrB  \n",
    "    --> bootstrap sample and bootstrap replicate based one shifted arrA(相当于重做N次实验) --> N个test stat\n",
    "    --> compare empirical test stat and experimental test stat, p-value\n",
    "    \n",
    "    \n",
    "* two sample test\n",
    "    * compare two sets of data: concatenate -> bs_resample -> each sample gives a bootstrap replicate(test statistic) -> compare test stat from observed data with them -> get p-value\n",
    "    * The permutation test exactly simulates the null hypothesis that the data come from the same distribution, whereas the bootstrap test approximately simulates it. As we will see, though, the bootstrap hypothesis test, while approximate, is more versatile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare permutation and bootstrap\n",
    "* permutation\n",
    "    *  two-sample hypothesis test ✔️/ one-sample hypothesis test ❌\n",
    "    * whether two sample have the same distribution✔️/ just have the same mean, not necessarily same dist. ❌\n",
    "    \n",
    "* bootstrap \n",
    "    * two-sample hypothesis test ✔️/ one-sample hypothesis test ✔️\n",
    "    * whether two sample have the same distribution ✔️ / just have the same mean, not necessarily same dist ✔️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Hypothesis test examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 A/B testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vote for the Civil Rights Act in 1964\n",
    "100xp\n",
    "The Civil Rights Act of 1964 was one of the most important pieces of legislation ever passed in the USA. Excluding \"present\" and \"abstain\" votes, 153 House Democrats and 136 Republicans voted yay. However, 91 Democrats and 35 Republicans voted nay. Did party affiliation make a difference in the vote?\n",
    "\n",
    "To answer this question, you will evaluate the hypothesis that the party of a House member has no bearing on his or her vote. You will use the fraction of Democrats voting in favor as your test statistic and evaluate the probability of observing a fraction of Democrats voting in favor at least as small as the observed fraction of 153/244. (That's right, at least as small as. In 1964, it was the Democrats who were less progressive on civil rights issues.) To do this, permute the party labels of the House voters and then arbitrarily divide them into \"Democrats\" and \"Republicans\" and compute the fraction of Democrats voting yay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct arrays of data: dems, reps\n",
    "dems = np.array([True] * 153 + [False] * 91)\n",
    "reps = np.array([True] * 136 + [False] * 35)\n",
    "\n",
    "def frac_yay_dems(dems, reps):\n",
    "    \"\"\"Compute fraction of Democrat yay votes.\"\"\"\n",
    "    frac = np.sum(dems) / len(dems)\n",
    "    return frac\n",
    "\n",
    "# Acquire permutation samples: perm_replicates\n",
    "perm_replicates = draw_perm_reps(dems, reps, frac_yay_dems, 10000)\n",
    "\n",
    "# Compute and print p-value: p\n",
    "p = np.sum(perm_replicates <= 153/244) / len(perm_replicates)\n",
    "print('p-value =', p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test of correlation\n",
    "（突然意识到用hacker stats来搬砖一个巨大的好处是很灵活，不用背鬼扯的公式。。。。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed correlation between female illiteracy and fertility in the data set of 162 countries may just be by chance; the fertility of a given country may actually be totally independent of its illiteracy. You will test this null hypothesis in the next exercise.\n",
    "\n",
    "To do the test, you need to simulate the data assuming the null hypothesis is true. Of the following choices, which is the best way to to do it?\n",
    "\n",
    "* A.Do a bootstrap sampling in which you sample 162 illiteracy values with replacement and then 162 fertility values with replacement.\n",
    "* ✔️B.Do a permutation test: Permute the illiteracy values but leave the fertility values fixed to generate a new set of (illiteracy, fertility) data.\n",
    "* C.Do a permutation test: Permute both the illiteracy and fertility values to generate a new set of (illiteracy, fertility data).  \n",
    "\n",
    "选项B比A更严谨，比C更computationally cheap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed correlation between female illiteracy and fertility may just be by chance; the fertility of a given country may actually be totally independent of its illiteracy. You will test this hypothesis. To do so, permute the illiteracy values but leave the fertility values fixed. This simulates the hypothesis that they are totally independent of each other. For each permutation, compute the Pearson correlation coefficient and assess how many of your permutation replicates have a Pearson correlation coefficient greater than the observed one.\n",
    "\n",
    "The function pearson_r() that you wrote in the prequel to this course for computing the Pearson correlation coefficient is already in your name space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute observed correlation: r_obs\n",
    "r_obs = pearson_r(illiteracy, fertility)\n",
    "\n",
    "# Initialize permutation replicates: perm_replicates\n",
    "perm_replicates = np.empty(10000)\n",
    "\n",
    "# Draw replicates\n",
    "for i in range(10000):\n",
    "    # Permute illiteracy measurments: illiteracy_permuted\n",
    "    illiteracy_permuted = np.random.permutation(illiteracy)\n",
    "\n",
    "    # Compute Pearson correlation\n",
    "    perm_replicates[i] = pearson_r(illiteracy_permuted, fertility)\n",
    "\n",
    "# Compute p-value: p\n",
    "p = np.sum(perm_replicates >= r_obs) / len(perm_replicates)\n",
    "print('p-val =', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Putting it all together: a case study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
