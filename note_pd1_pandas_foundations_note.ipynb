{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#0-pandas-basics\" data-toc-modified-id=\"0-pandas-basics-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>0 pandas basics</a></div><div class=\"lev1 toc-item\"><a href=\"#1-data-ingestion-&amp;-inspection\" data-toc-modified-id=\"1-data-ingestion-&amp;-inspection-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1 data ingestion &amp; inspection</a></div><div class=\"lev2 toc-item\"><a href=\"#1.1-building-dataframes-from-scratch\" data-toc-modified-id=\"1.1-building-dataframes-from-scratch-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>1.1 building dataframes from scratch</a></div><div class=\"lev2 toc-item\"><a href=\"#1.2-importing-&amp;-exporting-data\" data-toc-modified-id=\"1.2-importing-&amp;-exporting-data-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>1.2 importing &amp; exporting data</a></div><div class=\"lev2 toc-item\"><a href=\"#1.3-plotting-with-pandas\" data-toc-modified-id=\"1.3-plotting-with-pandas-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>1.3 plotting with pandas</a></div><div class=\"lev1 toc-item\"><a href=\"#2-exploratory-data-analysis\" data-toc-modified-id=\"2-exploratory-data-analysis-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2 exploratory data analysis</a></div><div class=\"lev2 toc-item\"><a href=\"#2.1-visual-explotatory-data-analysis-(numerical-vals)\" data-toc-modified-id=\"2.1-visual-explotatory-data-analysis-(numerical-vals)-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>2.1 visual explotatory data analysis (numerical vals)</a></div><div class=\"lev2 toc-item\"><a href=\"#2.2-statistical-exploratory-data-analysis-(for-numerical-columns-)\" data-toc-modified-id=\"2.2-statistical-exploratory-data-analysis-(for-numerical-columns-)-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>2.2 statistical exploratory data analysis (for numerical columns )</a></div><div class=\"lev2 toc-item\"><a href=\"#2.3-separating-populations-(for-categorical-columns-)\" data-toc-modified-id=\"2.3-separating-populations-(for-categorical-columns-)-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>2.3 separating populations (for categorical columns )</a></div><div class=\"lev1 toc-item\"><a href=\"#3-using-pandas-to-model-time-series\" data-toc-modified-id=\"3-using-pandas-to-model-time-series-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3 using pandas to model time series</a></div><div class=\"lev2 toc-item\"><a href=\"#3.1-indexing-time-series\" data-toc-modified-id=\"3.1-indexing-time-series-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>3.1 indexing time series</a></div><div class=\"lev2 toc-item\"><a href=\"#3.2-resampling-time-series-data\" data-toc-modified-id=\"3.2-resampling-time-series-data-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>3.2 resampling time series data</a></div><div class=\"lev2 toc-item\"><a href=\"#3.3-manipulating-time-series-data\" data-toc-modified-id=\"3.3-manipulating-time-series-data-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>3.3 manipulating time series data</a></div><div class=\"lev2 toc-item\"><a href=\"#3.4-time-series-visualization\" data-toc-modified-id=\"3.4-time-series-visualization-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>3.4 time series visualization</a></div><div class=\"lev1 toc-item\"><a href=\"#4-case-study:-sunlight-in-Austin\" data-toc-modified-id=\"4-case-study:-sunlight-in-Austin-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>4 case study: sunlight in Austin</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 pandas basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# don't run the cells\n",
    "\n",
    "# indexes and columns\n",
    "type(df)\n",
    "df.shape # access the shape attribute\n",
    "\n",
    "df.columns\n",
    "type(df.columns)\n",
    "\n",
    "df.index\n",
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slicing\n",
    "df.loc[rows, cols] # slicing by label index  \n",
    "\n",
    "df.iloc[rows, cols] # slicing by position index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looking at the data frame \n",
    "df.head()  \n",
    "df.tail()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 data ingestion & inspection  \n",
    "\n",
    "data import & export in various format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 building dataframes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframes from csv files\n",
    "pd.read_csv(filepath, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe from dict (1)\n",
    "dict = {'colA':[lst_of_vals], \n",
    "        'colB':[lst_of_vals],\n",
    "        'colC':[lst_of_vals]}\n",
    "\n",
    "pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframes from dict(2)\n",
    "colA = [lst_of_vals]\n",
    "colB = [lst_of_vals]\n",
    "colC = [lst_of_vals]\n",
    "\n",
    "names = ['nameA', 'nameB', 'nameC']\n",
    "cols = [colA, colB, colC] # a list of lists, containing values of a df\n",
    "\n",
    "zipped = list(zip(names, cols)) # return a list of tuples\n",
    "\n",
    "data = dict(zipped) # convert the list of tuples to dict\n",
    "\n",
    "pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# broadcasting(1)\n",
    "df['someCol'] = 0 # assign 0 to the entire column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# broadcasting(2)\n",
    "data = {'nameA':[lst_of_vals],\n",
    "        'nameB':a_single_val}\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set index and columns \n",
    "df.columns = [lst_of_col_names_you_want]\n",
    "df.index = [lst_of_inx_names_you_want]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 importing & exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datasets from csv\n",
    "\n",
    "col_names = [lst_of_col_names_you_want]\n",
    "\n",
    "pd.read_csv(filepath, \n",
    "            header = None # tell pandas there's no header line in source file \n",
    "            name = col_names # tell pandas to use col_names you desire\n",
    "            na_values = {'colA':['-1']} # tell pandas the '-1' in column A is NaN value\n",
    "            parse_dates = [[0, 1, 2]] # tell pd the value in column [0,1,2] should be concatenated and treated as date\n",
    "            # or:\n",
    "            parse_dates = True # or to parse the col containing complete date string)\n",
    "\n",
    "# inspecting dataframe\n",
    "df.info()\n",
    "\n",
    "# using dates as index\n",
    "df.index = df['dateCol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exporting data \n",
    "\n",
    "df.to_csv('output.csv') # to .csv\n",
    "\n",
    "df.to_csv('output.tsv', sep = '\\t') # to .tsv\n",
    "\n",
    "df.to_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropping columns / trimming off redundant columns \n",
    "cols_to_keep = [colA, colB]\n",
    "\n",
    "df = df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 plotting with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting numpy arrays (matplotlib)\n",
    "plt.plot(some_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting pandas Series\n",
    "plt.plot(some_series) # using matplotlib\n",
    "plt.show()\n",
    "\n",
    "some_series.plot() # using pandas, plot Series derectly\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting pandas DataFrames\n",
    "plt.plot(df)  # using matplotlib, plot all columns at once \n",
    "plt.show()\n",
    "\n",
    "\n",
    "df.plot()  # using pandas, plot all Series at once\n",
    "plt.show()\n",
    "\n",
    "# fixing scales\n",
    "df.plot()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# customizing plots\n",
    "some_series.plot(color = 'b',\n",
    "                 style = '.-', \n",
    "                 legend = True)\n",
    "\n",
    "plt.axis(start_of_x, end_of_x, start_of_y, end_of_y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving plots\n",
    "plt.savefig('picname.png')\n",
    "\n",
    "plt.savefig('picname.jpg')\n",
    "\n",
    "plt.savefig('picname.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 exploratory data analysis\n",
    "\n",
    "statistical & graphical methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 visual explotatory data analysis (numerical vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath, index_col = 0)\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.plot(x = col_as_x, y = col_as_y, \n",
    "        kind = 'scatter' | kind = 'box' | kind = 'hist')\n",
    "\n",
    "plt.xlabel(label_on_x_axis)\n",
    "plt.ylabel(label_on_y_axis)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when kind = 'hist', there's some more options\n",
    "\n",
    "df1.plot(x = col_as_x, y = col_as_y, \n",
    "        kind = 'hist',\n",
    "        bins = 30, # number of interval or bins\n",
    "        range = (4, 8), # extrema of bins (min, max) \n",
    "        normed = True, # whether to normalize frequency to 1)\n",
    "\n",
    "df2.plot(x = col_as_x, y = col_as_y, \n",
    "        kind = 'hist',\n",
    "        bins = 30, # number of interval or bins\n",
    "        range = (4, 8), # extrema of bins (min, max) \n",
    "        normed = True, # whether to normalize frequency to 1, \n",
    "        cumulative = True # Cumulative Distribution Function (CDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# different DataFrame plot idoms\n",
    "df.plot(kind = 'hist')\n",
    "\n",
    "df.plt.hist()\n",
    "\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 同时画多个图(like gridExtra in R)\n",
    "    # one way is to use df.plot(subplot=True)\n",
    "    # another is to format the plot like this:  \n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "    # Plot the PDF\n",
    "df.fraction.plot(ax=axes[0], kind='hist', normed=True, \n",
    "                 bins=30, range=(0,.3))\n",
    "plt.show()\n",
    "\n",
    "    # Plot the CDF\n",
    "df.fraction.plot(ax=axes[1], kind='hist', normed=True, \n",
    "                 cumulative=True, bins=30, range=(0,.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 statistical exploratory data analysis (for numerical columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarizing with describe()\n",
    "df.describe() # get count, mean,std, min, 25%, 50%, 75%, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count\n",
    "df[colA].count() # apply to Series, get an int \n",
    "df[colB].count()\n",
    "\n",
    "df[[colA, colB]].count() # apply to DataFrame, get a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# averages \n",
    "df[colA].mean() # apply to Series\n",
    "\n",
    "df.mean() # apply to entire DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard deviations \n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# median & 0.5 quantile\n",
    "df.meidan()\n",
    "\n",
    "q = 0.5\n",
    "df.quantile(q) # gets the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inter-quartile range(IQR)\n",
    "q = [0.25, 0.75]\n",
    "\n",
    "df.quantile(q) # get a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ranges\n",
    "df.min()\n",
    "\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# box plots\n",
    "df.plot(kind = 'box') # plotting all columns \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 separating populations (for categorical columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe categorical column\n",
    "df[cate_col].describe() \n",
    "    # count: non-null entries\n",
    "    # unique: distinct values\n",
    "    # top: most frequent category\n",
    "    # freq: occurrency of the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unique factors\n",
    "df[cate_col].unique()\n",
    "\n",
    "# occurences of each unique val\n",
    "df[cate_col].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filtering by species\n",
    "indices = df[cate_col] == 'typeA'\n",
    "\n",
    "typeA = df.loc[indices, :]  # extracting new DataFrame\n",
    "\n",
    "typeA[cate_col].unique() # expect only one value\n",
    "\n",
    "typeB = df.loc[df[cate_col] == 'typeB', :]\n",
    "typeC = df.loc[df[cate_col] == 'typeC', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot numerical columns seperated by categorical values\n",
    "typeA.plot(kind = 'hist', bins = 50, range = (0, 8), alpha = 0.3)\n",
    "\n",
    "typeB.plot(kind = 'hist', bins = 50, range = (0, 8), alpha = 0.3)\n",
    "\n",
    "typeC.plot(kind = 'hist', bins = 50, range = (0, 8), alpha = 0.3)\n",
    "\n",
    "    # get one plot each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 using pandas to model time series\n",
    "\n",
    "time indexes, resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 indexing time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use pandas to read datetime objects\n",
    "df = pd.read_csv(filepath, \n",
    "            parse_dates = True, # read string s into datetime obj\n",
    "            index_col = 'date' # specify the column name in the souce df\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Partial datetime string selection\n",
    "df.loc['2015-02-19 11:00:00', 'colA'] # selecting single cell\n",
    "\n",
    "# selecting the whole day\n",
    "sales.loc['2015-2-5']\n",
    "\n",
    "sales.loc['2015-2'] # Whole month\n",
    "sales.loc['2015'] # Whole year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slicing using dates/times\n",
    "sales.loc['2015-2-16':'2015-2-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert strings to datetime\n",
    "evening_2_11 = pd.to_datetime(['2015-2-11 20:00', \n",
    "                               '2015-2-11 21:00', \n",
    "                               '2015-2-11 22:00', \n",
    "                               '2015-2-11 23:00'])\n",
    "\n",
    "sales.reindex(evening_2_11) # replace index with the above lst_of_date_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "\n",
    "# reindex with [dateA, dateB, dateC, dateD],\n",
    "# it's like rearranging data, not literally changing their index.\n",
    "# say when the source don't have dateB, dateC row\n",
    "# the new df will have NaN value in dateB, dateC row\n",
    "\n",
    "sales.reindex(evening_2_11, method='ffill') # 向前看齐\n",
    "\n",
    "sales.reindex(evening_2_11, method='bfill') # 向后看齐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 resampling time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales-feb-2015.csv',\n",
    "                    parse_dates=True,\n",
    "                    index_col= 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resampling: 调整看数据的尺度\n",
    "    # down-sampling：退后几步，从更大的时间单位看\n",
    "    # up-sampling：走朝前，从更精细的时间单位看\n",
    "    \n",
    "# resampling together used with aggregation functions\n",
    "    # mean(), sum(), median(), count(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Aggregating \n",
    "daily_mean = sales.resample('D').mean()\n",
    "\n",
    "sales.resample('D').sum()\n",
    "\n",
    "sales.resample('W').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method chaining\n",
    "sales.resample('D').sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resampling frequencies  \n",
    "![](http://upload-images.jianshu.io/upload_images/1526845-2e69cd2286eef6f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multiplying frequencies\n",
    "sales.loc[:,'Units'].resample('2W').sum() # 每两周为一个group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upsampling and filling \n",
    "two_days.resample('4H').ffill() # 每4小时为一个group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smoothing short-term fluctuations using .rolling()\n",
    "hourly_data.rolling(window=24).mean()  # 把每个点之前的24个点aggre起来求均值\n",
    "                                       # 会导致前24个点的y消失掉哦，因为它们之前并不够24点来一起求均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 manipulating time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(filepath, \n",
    "                    parse_dates = ['Date'] # specify the column containing date str\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# string methods\n",
    "\n",
    "sales[colA].str.upper() # turn vals in colA into upper case\n",
    "\n",
    "sales[colB].str.contains(some_word) # get a Series of boolean\n",
    "\n",
    "sales[colC].str.strip()  # strip extra whitespace\n",
    "\n",
    "sales[colD].str.contains(some_word).sum() # the sum of 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Datetime methods\n",
    "\n",
    "sales['Date'].dt.hour # extract hour in datetime obj\n",
    "\n",
    "central = sales['Date'].dt.tz_localize('US/Central') # set timezone \n",
    "central.dt.tz_convert('US/Eastern')  # convert timezone\n",
    "\n",
    "sales['Dates'].dt.tz_localize('US/Central').dt.tz_convert('US/Eastern') # method chaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interpolate missing data\n",
    "\n",
    "    # this data set contains world population every 10 years\n",
    "population = pd.read_csv('world_population.csv',\n",
    "                         parse_dates=True, \n",
    "                         index_col= 'Date')\n",
    "\n",
    "    # rather than ffill or bfill, \n",
    "    # tell pandas to generate a linear model to fit missing values \n",
    "population.resample('A').first().interpolate('linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 time series visualization\n",
    "\n",
    "* line types \n",
    "* plot types \n",
    "* subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp500.loc['2012-4', 'Close'].plot(style='k.-',\n",
    "                                  title='S&P500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kind option, kind = 'area'\n",
    "sp500['Close'].plot(kind='area', title='S&P 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot multiple columns \n",
    "sp500.loc['2012', ['Close','Volume']].plot() # two cols in one plot\n",
    "\n",
    "sp500.loc['2012', ['Close','Volume']].plot(subplots=True) # two cols in separate plots\n",
    "                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4 case study: sunlight in Austin\n",
    "* 一些之前的笔记中没有提及的细节tech  \n",
    "    * [Python String Format Cookbook](https://mkaz.tech/code/python-string-format-cookbook/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "297px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "491px",
    "left": "0px",
    "right": "818px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
