{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0 pandas basics\n",
    "* 1 data ingestion & inspection\n",
    "    * 1.1 building dataframes from scratch\n",
    "    * 1.2 importing & exporting data\n",
    "    * 1.3 plotting with pandas\n",
    "* 2 exploratory data analysis\n",
    "    * 2.1 visual explotatory data analysis (numerical vals)\n",
    "    * 2.2 statistical exploratory data analysis (for numerical columns )\n",
    "    * 2.3 separating populations (for categorical columns )\n",
    "* 3 using pandas to model time series\n",
    "    * 3.1 indexing time series\n",
    "    * 3.2 resampling time series data\n",
    "    * 3.3 manipulating time series data\n",
    "    * 3.4 time series visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 pandas basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# don't run the cells\n",
    "\n",
    "# indexes and columns\n",
    "type(df)\n",
    "\n",
    "df.shape # access the shape attribute\n",
    "\n",
    "df.columns\n",
    "\n",
    "type(df.columns)\n",
    "\n",
    "df.index\n",
    "\n",
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slicing\n",
    "df.loc[rows, cols] # slicing by label index  \n",
    "\n",
    "df.iloc[rows, cols] # slicing by position index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looking at the data frame \n",
    "df.head()  \n",
    "\n",
    "df.tail()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 data ingestion & inspection  \n",
    "\n",
    "data import & export in various format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 building dataframes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframes from csv files\n",
    "pd.read_csv(filepath, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe from dict (1)\n",
    "dict = {'colA':[lst_of_vals], \n",
    "        'colB':[lst_of_vals],\n",
    "        'colC':[lst_of_vals]}\n",
    "\n",
    "pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframes from dict(2)\n",
    "colA = [lst_of_vals]\n",
    "colB = [lst_of_vals]\n",
    "colC = [lst_of_vals]\n",
    "\n",
    "names = ['nameA', 'nameB', 'nameC']\n",
    "cols = [colA, colB, colC] # a list of lists, containing values of a df\n",
    "\n",
    "zipped = list(zip(names, cols)) # return a list of tuples\n",
    "\n",
    "data = dict(zipped) # convert the list of tuples to dict\n",
    "\n",
    "pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# broadcasting(1)\n",
    "df['someCol'] = 0 # assign 0 to the entire column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# broadcasting(2)\n",
    "data = {'nameA':[lst_of_vals],\n",
    "        'nameB':a_single_val}\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set index and columns \n",
    "df.columns = [lst_of_col_names_you_want]\n",
    "df.index = [lst_of_inx_names_you_want]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 importing & exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datasets from csv\n",
    "\n",
    "col_names = [lst_of_col_names_you_want]\n",
    "\n",
    "pd.read_csv(filepath, \n",
    "            header = None # tell pandas there's no header line in source file \n",
    "            name = col_names # tell pandas to use col_names you desire\n",
    "            na_values = {'colA':['-1']} # tell pandas the '-1' in column A is NaN value\n",
    "            parse_dates = [[0, 1, 2]] # tell pd the value in column [0,1,2] should be concatenated and treated as date\n",
    "            parse_dates = True # or to parse the col containing complete date string)\n",
    "\n",
    "# inspecting dataframe\n",
    "df.info()\n",
    "\n",
    "# using dates as index\n",
    "df.index = df['dateCol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exporting data \n",
    "\n",
    "df.to_csv('output.csv') # to .csv\n",
    "\n",
    "df.to_csv('output.tsv', sep = '\\t') # to .tsv\n",
    "\n",
    "df.to_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropping columns / trimming off redundant columns \n",
    "cols_to_keep = [colA, colB]\n",
    "\n",
    "df = df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 plotting with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting numpy arrays (matplotlib)\n",
    "plt.plot(some_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting pandas Series\n",
    "plt.plot(some_series) # using matplotlib\n",
    "plt.show()\n",
    "\n",
    "some_series.plot() # using pandas, plot Series derectly\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting pandas DataFrames\n",
    "plt.plot(df)  # using matplotlib, plot all columns at once \n",
    "plt.show()\n",
    "\n",
    "\n",
    "df.plot()  # using pandas, plot all Series at once\n",
    "plt.show()\n",
    "\n",
    "# fixing scales\n",
    "df.plot()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# customizing plots\n",
    "some_series.plot(color = 'b',\n",
    "                 style = '.-', \n",
    "                 legend = True)\n",
    "\n",
    "plt.axis(start_of_x, end_of_x, start_of_y, end_of_y)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving plots\n",
    "plt.savefig('picname.png')\n",
    "\n",
    "plt.savefig('picname.jpg')\n",
    "\n",
    "plt.savefig('picname.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 exploratory data analysis\n",
    "\n",
    "statistical & graphical methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 visual explotatory data analysis (numerical vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath, index_col = 0)\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.plot(x = col_as_x, y = col_as_y, \n",
    "        kind = 'scatter' | kind = 'box' | kind = 'hist')\n",
    "\n",
    "plt.xlabel(label_on_x_axis)\n",
    "plt.ylabel(label_on_y_axis)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when kind = 'hist', there's some more options\n",
    "\n",
    "df1.plot(x = col_as_x, y = col_as_y, \n",
    "        kind = 'hist',\n",
    "        bins = 30, # number of interval or bins\n",
    "        range = (4, 8), # extrema of bins (min, max) \n",
    "        normed = True, # whether to normalize frequency to 1)\n",
    "\n",
    "df2.plot(x = col_as_x, y = col_as_y, \n",
    "        kind = 'hist',\n",
    "        bins = 30, # number of interval or bins\n",
    "        range = (4, 8), # extrema of bins (min, max) \n",
    "        normed = True, # whether to normalize frequency to 1, \n",
    "        cumulative = True # Cumulative Distribution Function (CDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# different DataFrame plot idoms\n",
    "df.plot(kind = 'hist')\n",
    "\n",
    "df.plt.hist()\n",
    "\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 statistical exploratory data analysis (for numerical columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarizing with describe()\n",
    "df.describe() # get count, mean,std, min, 25%, 50%, 75%, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count\n",
    "df[colA].count() # apply to Series, get an int \n",
    "df[colB].count()\n",
    "\n",
    "df[[colA, colB]].count() # apply to DataFrame, get a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# averages \n",
    "df[colA].mean() # apply to Series\n",
    "\n",
    "df.mean() # apply to entire DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard deviations \n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# median & 0.5 quantile\n",
    "df.meidan()\n",
    "\n",
    "q = 0.5\n",
    "df.quantile(q) # gets the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inter-quartile range(IQR)\n",
    "q = [0.25, 0.75]\n",
    "\n",
    "df.quantile(q) # get a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ranges\n",
    "df.min()\n",
    "\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# box plots\n",
    "df.plot(kind = 'box') # plotting all columns \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 separating populations (for categorical columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe categorical column\n",
    "df[cate_col].describe() \n",
    "    # count: non-null entries\n",
    "    # unique: distinct values\n",
    "    # top: most frequent category\n",
    "    # freq: occurrency of the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unique factors\n",
    "df[cate_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filtering by species\n",
    "indices = df[cate_col] == 'typeA'\n",
    "\n",
    "typeA = df.loc[indices, :]  # extracting new DataFrame\n",
    "\n",
    "typeA[cate_col].unique() # expect only one value\n",
    "\n",
    "typeB = df.loc[df[cate_col] == 'typeB', :]\n",
    "typeC = df.loc[df[cate_col] == 'typeC', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot numerical columns seperated by categorical values\n",
    "typeA.plot(kind = 'hist', bins = 50, range = (0, 8), alpha = 0.3)\n",
    "\n",
    "typeB.plot(kind = 'hist', bins = 50, range = (0, 8), alpha = 0.3)\n",
    "\n",
    "typeC.plot(kind = 'hist', bins = 50, range = (0, 8), alpha = 0.3)\n",
    "\n",
    "    # get one plot each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 using pandas to model time series\n",
    "\n",
    "time indexes, resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 indexing time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use pandas to read datetime objects\n",
    "df = pd.read_csv(filepath, \n",
    "            parse_dates = True, # read string s into datetime obj\n",
    "            index_col = 'date' # specify the column name in the souce df\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Partial datetime string selection\n",
    "df.loc['2015-02-19 11:00:00', 'colA'] # selecting single cell\n",
    "\n",
    "# selecting the whole day\n",
    "sales.loc['2015-2-5']\n",
    "\n",
    "sales.loc['2015-2'] # Whole month\n",
    "sales.loc['2015'] # Whole year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slicing using dates/times\n",
    "sales.loc['2015-2-16':'2015-2-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert strings to datetime\n",
    "evening_2_11 = pd.to_datetime(['2015-2-11 20:00', \n",
    "                               '2015-2-11 21:00', \n",
    "                               '2015-2-11 22:00', \n",
    "                               '2015-2-11 23:00'])\n",
    "\n",
    "sales.reindex(evening_2_11) # replace index with the above lst_of_date_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "\n",
    "# reindex with [dateA, dateB, dateC, dateD],\n",
    "# it's like rearranging data, not literally changing their index.\n",
    "# say when the source don't have dateB, dateC row\n",
    "# the new df will have NaN value in dateB, dateC row\n",
    "\n",
    "sales.reindex(evening_2_11, method='ffill') # 向前看齐\n",
    "\n",
    "sales.reindex(evening_2_11, method='bfill') # 向后看齐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 resampling time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales-feb-2015.csv',\n",
    "                    parse_dates=True,\n",
    "                    index_col= 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resampling: 调整看数据的尺度\n",
    "    # down-sampling：退后几步，从更大的时间单位看\n",
    "    # up-sampling：走朝前，从更精细的时间单位看\n",
    "    \n",
    "# resampling together used with aggregation functions\n",
    "    # mean(), sum(), median(), count(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Aggregating \n",
    "daily_mean = sales.resample('D').mean()\n",
    "\n",
    "sales.resample('D').sum()\n",
    "\n",
    "sales.resample('W').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method chaining\n",
    "sales.resample('D').sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resampling frequencies  \n",
    "![](http://note.youdao.com/yws/public/resource/5875cbf527e0463ea3b90059c233b97c/xmlnote/WEBRESOURCE51e6e58394e4d043093e6fea984ccf3a/30104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# multiplying frequencies\n",
    "sales.loc[:,'Units'].resample('2W').sum() # 每两周为一个group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upsampling and filling \n",
    "two_days.resample('4H').ffill() # 每4小时为一个group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 manipulating time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(filepath, \n",
    "                    parse_dates = ['Date'] # specify the column containing date str\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# string methods\n",
    "\n",
    "sales[colA].str.upper() # turn vals in colA into upper case\n",
    "\n",
    "sales[colB].str.contains(some_word) # get a Series of boolean\n",
    "\n",
    "sales[colB].str.contains(some_word).sum() # the sum of 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Datetime methods\n",
    "\n",
    "sales['Date'].dt.hour # extract hour in datetime obj\n",
    "\n",
    "central = sales['Date'].dt.tz_localize('US/Central') # set timezone \n",
    "central.dt.tz_convert('US/Eastern')  # convert timezone\n",
    "\n",
    "sales['Dates'].dt.tz_localize('US/Central').dt.tz_convert('US/Eastern') # method chaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interpolate missing data\n",
    "\n",
    "    # this data set contains world population every 10 years\n",
    "population = pd.read_csv('world_population.csv',\n",
    "                         parse_dates=True, \n",
    "                         index_col= 'Date')\n",
    "\n",
    "    # rather than ffill or bfill, \n",
    "    # tell pandas to generate a linear model to fit missing values \n",
    "population.resample('A').first.interpolate('linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 time series visualization\n",
    "\n",
    "* line types \n",
    "* plot types \n",
    "* subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp500.loc['2012-4', 'Close'].plot(style='k.-',\n",
    "                                  title='S&P500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* line types options of pd.Series.plot()\n",
    "\n",
    "![](http://note.youdao.com/yws/public/resource/5875cbf527e0463ea3b90059c233b97c/xmlnote/WEBRESOURCEb1287b52558aa1bc40d6ee62091a794d/30108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kind option, kind = 'area'\n",
    "sp500['Close'].plot(kind='area', title='S&P 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot multiple columns \n",
    "sp500.loc['2012', ['Close','Volume']].plot() # two cols in one plot\n",
    "\n",
    "sp500.loc['2012', ['Close','Volume']].plot(subplots=True) # two cols in separate plots\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
